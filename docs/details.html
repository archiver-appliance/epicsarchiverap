<!DOCTYPE html>
<html>
<head>
<meta charset="ISO-8859-1">
<title>EPICS Archiver Appliance - Details</title>
<link type="text/css" href="docs.css" rel="Stylesheet" />	
</head>
<body>
<!-- Header starts here -->
<h1 id="title"><span><a href="index.html">EPICS Archiver Appliance</a></span><img src="images/Icon_Mathematical_Plot.png"/></h1>
<div id="wrap">
<div id="topbar">
Last published on {publish_date}.
</div>
<aside id="leftnav">
<div id="leftnavtitle"><span>EPICS Archiver Appliance</span></div>
<ol>
<li><a href="https://sourceforge.net/p/epicsarchiverap/news/">News</a></li>
<li><a href="details.html">Details</a></li>
<li><a href="https://sourceforge.net/projects/epicsarchiverap/files/">Download</a></li>
<li><a href="quickstart.html">Quickstart</a></li>
<li><a href="installguide.html">Installation</a></li>
<li><a href="userguide.html">User Guide</a></li>
<li><a href="customization.html">Customize</a></li>
<li><a href="developersguide.html">Developers</a></li>
<li><a href="api/index.html">Javadoc</a></li>
<li><a href="https://sourceforge.net/p/epicsarchiverap/bugs/">Issues</a></li>
<li><a href="faq.html">FAQ</a></li>
<li><a href="license.html">License</a></li>
</ol>
</aside>
<!-- Header ends here -->

<article id="rightcontent">

<div id="intro">
This is an implementation of an archiver for <a href="http://www.aps.anl.gov/epics/index.php">EPICS</a> control systems that aims to archive millions of PVs.
</div>


<section>
Here are the main features.
<ul>
<li>Ability to cluster appliances and to scale by adding appliances to the cluster.</li>
<li>Multiple stages and an inbuilt process to move data between the stages.
<ul>
<li>This supports the ability to use faster storage (which is perhaps limited in size) to improve performance.</li>
<li>Ability to reduce (decimate) the data as it moves into a store.</li>
</ul>
</li>
<li>Focus on data retrieval performance.</li>
<li>A management interface giving you the ability to manage and monitor the system using a browser. This includes
<ol>
<li>The ability to add PVs to a cluster of appliances using a browser (perhaps by users).</li>
<li>Various metrics to help with capacity planning.</li>
<li>Ability to define system-wide defaults for archiving parameters using policies.</li>
</ol>
</li>
<li>Ability to script the business processes in the appliances using an external process in a language like <a href="http://www.python.org/">Python</a>.</li>
<li>Ability to configure various archiving parameters on a per PV basis.</li>
<li>Ability to customize the appliance to suit a different set of requirements. This includes
<ul>
<li>The ability to use alternate storage technologies that may better suit your needs or perform better in your environment.</li>
<li>The ability to define your own data reduction algorithms and to optionally cache data generated by these algorithms on a per PV basis.</li>
<li>Simple ways to add support for new MIME types in data retrieval responses.</li>
</ul>
</li>
<li>Support for EPICS aliases.</li>
<li>Support for retrieval of data using <a href="archiveviewer.html">ArchiveViewer</a>, the CSS databrowser and Matlab.</li>
<li>Limited integration with existing Channel Archiver data sources.</li>
</ul>
</section>

<section id="SystemRequirements">
<h3>System requirements</h3>
These are the prerequisites for the EPICS archiver appliance.
<ul>
<li>A recent version of Linux, definitely 64 bit Linux for production systems. If using RedHat, we should aim for RedHat 6.1.</li>
<li>Sun Java JDK 1.7 (update 6 or later) - definitely the 64 bit version for production systems. We need the JDK, <b>not</b> the JRE.</li>
<li>A recent version of Tomcat 7.x; preferably <code>apache-tomcat-7.0.22</code> or later.</li>
<li>The management UI works best with a recent version of Firefox or Chrome.</li>
<li>By default, the EPICS archiver appliance uses a bundled version of <a href="http://epics-jca.sourceforge.net/caj/">CAJ</a>.</li>
</ul>

Optionally, we'd need
<ul>
<li>A recent version of MySQL <code>mysql-5.1</code> or later if persisting configuration to a database.
We hope to add Postgres support soon.
</li>
</ul>

In terms of hardware, for production systems, we'd need a reasonably powerful server box with lots of memory for each appliance. 
For example, we plan to use 24 core machines with at least 32GB of memory and a SSD/flash drive for medium term storage. 

</section>



<section>
<h3>Storage</h3>
Out of the box, the following storage technologies/plugins are supported.
<ul class="definition">
<li><span class="definitionterm"><a href="api/edu/stanford/slac/archiverappliance/PlainPB/PlainPBStoragePlugin.html">PlainPBStoragePlugin</a></span>
<span class="definition">This plugin serializes samples using Google's <a href="https://developers.google.com/protocol-buffers">ProtocolBuffers</a> and stores data in chunks.
Each chunk has a well defined key and stores data for one PV for a well defined time duration (for example, a month).
Using Java <a href="http://docs.oracle.com/javase/7/docs/api/java/nio/file/package-summary.html">NIO2</a>, one can store each chunk in 
</span>
<ol>
<li>A file per chunk resulting in a file per PV per time partition.</li>
<li>A zip file entry in a <code>.zip</code> file per chunk resulting in a <code>.zip</code> file per PV.</li>
<li>This can be extended to use other storage technologies for which a NIO2 provider is available (for example, a database BLOB per chunk or a key/value pair per chunk in any key/value store).</li>
</ol>
<div class="noteafterlist">By default, the PlainPBStoragePlugin maps PV names to keys using a simple algorithm that relies on the presence of a good PV naming convention. To use your own mapping scheme, see the <a href="customization.html#PVNamesToKeys">Key Mapping</a> section in the customization guide.</div>    
</li>
</ul>
To add support for other storage technologies - see the <a href="customization.html#key_mapping">customization guide</a> for details.
</section>

<section>
<h3>Architecture</h3>
Each appliance consists of 4 modules deployed in Tomcat containers as separate <a href="http://en.wikipedia.org/wiki/WAR_file_format_%28Sun%29">WAR</a> files.
For production systems, it is recommended that each module be deployed in a separate Tomcat instance (thus yielding four Tomcat processes).
A sample storage configuration is outlined below where we'd use
<ol>
<li>Ramdisk for the short term store - in this storage stage, we'd store data at a granularity of an hour.</li>
<li>A SSD for the medium term store - in this storage stage, we'd store data at a granularity of a day.</li>
<li>A NAS/SAN for the long term store - in this storage stage, we'd store data at a granularity of a year.</li>
</ol> 
<figure>
<img src="images/applarch.png"/>
<figcaption>Architecture of a single appliance</figcaption>
</figure>
<div>
A wide variety of such configurations is possible and supported.
For example, if you have a powerful enough NAS/SAN, you could write straight to the long term store; bypassing all the stages in between.
</div>

<div>
The long term store is shown outside the appliance as an example of a commonly deployed configuration.
There is no necessity for the appliances to share any storage; so both of these configurations are possible.
<figure>
<img src="images/clusterinto1lts.png" alt="Multiple appliances into one long term store"/>
<figcaption>Multiple appliances sending data into one long term store</figcaption> 
</figure>
<figure>
<img src="images/clusterintodifflts.png" alt="Multiple appliances into different long term stores"/>
<figcaption>Multiple appliances sending data into different long term stores</figcaption> 
</figure>
</div>

</section>

<section>
<h3>Policies</h3>
All of the various configurations can get quite tricky for end users to navigate. 
Rather than expose all of this variation to the end users and to provide a simple interface to end users, the archiver appliance uses <a href="api/org/epics/archiverappliance/mgmt/policy/package-summary.html">policies</a></code>.
Policies are Python scripts that make these decisions on behalf of the users. 
Policies are site-specific and identical across all appliances in the cluster.
When a user requests a new PV to be archived, the archiver appliance samples the PV to determine event rate, storage rate and other parameters.
In addition, various fields of the PV like .NAME, .ADEL, .MDEL, .RTYP etc are also obtained.
These are passed to the policies python script which then has some simple code to configure the detailed archival parameters.
The archiver appliance executes the <code>policies.py</code> python script using an embedded <a href="http://www.jython.org/">jython</a> interpreter.
Policies allow system administrators to support a wide variety of configurations that are more appropriate to their infrastructure without exposing the details to their users.
</section>

<section>
<h3>Clustering</h3>
<p>
While each appliance in a cluster is independent and self-contained, all members of a cluster are listed in a special configuration file (typically called <a href="installguide.html#appliances_xml">appliances.xml</a>) that is site-specific and identical across all appliances in the cluster.
 The <code>appliances.xml</code> is a simple XML file that contains the ports and URLs of the various webapps in that appliance.
Each appliance has a dedicated TCP/IP endpoint called <code>cluster_inetport</code> for cluster operations like cluster membership etc..
One startup, the <code>mgmt</code> webapp uses the <code>cluster_inetport</code> of all the appliances in <code>appliances.xml</code> to discover other members of the cluster.
This is done using TCP/IP only (no need for broadcast/multicast support).
</p>

<p>
The business processes are all cluster-aware; the bulk of the inter-appliance communication that happens as part of normal operation is accomplished using JSON/HTTP on the other URLs defined in <code>appliances.xml</code>.
All the JSON/HTTP calls from the mgmt webapp are also available to you for use in scripting, see the section on <a href="#scripting">scripting</a>.
</p>

<p>
The archiving functionality is split across members of the cluster; that is, each PV that is being archived is being archived by one appliance in the cluster.

However, both data retrieval and business requests can be dispatched to any random appliance in the cluster; the appliance has the functionality to route/proxy the request accordingly.
</p>

<figure>
<img src="images/proxyrequest.png"/>
<figcaption>Appliance 1 proxies data retrieval request for PV being archived by appliance 2.</figcaption>
</figure> 
In addition, users do not need to allocate PVs to appliances when requesting for new PVs be archived.
The appliances maintain a small set of metrics during their operation and use this in addition to the measured event and storage rates to do <a href="api/org/epics/archiverappliance/mgmt/archivepv/CapacityPlanningBPL.html">Capacity Planning</a>/load balancing. 
</section>

<section id="scripting">
<h3>Scripting</h3>
The archiver appliance comes with a web interface that has support for various business processes. 
The web interface communicates with the server principally using JSON/HTTP. 
The same web service calls are also available for use from external scripting tools like Python. 
<figure>
<img src="images/pythonscript.png"/>
<figcaption>A sample python script that prints out all the PVs in the cluster of appliances.</figcaption>
</figure> 
Click <a href="api/mgmt_scriptables.html" target="_blank">here</a> for a list of business logic accesible thru scripting.
</section>

<section>
<h3>Screenshots</h3>
<figure>
<img src="images/homepage.png"/>
<figcaption>A screenshot of the home page.</figcaption>
</figure> 

<figure>
<img src="images/reportspage.png"/>
<figcaption>We offer a wide variety of reports.</figcaption>
</figure> 

<figure>
<img src="images/metricspage.png"/>
<figcaption>Metrics maintained by the appliances.</figcaption>
</figure> 

<figure>
<img src="images/appliancespage.png"/>
<figcaption>The appliances page offers a quick view of some JVM parameters.</figcaption>
</figure> 

</section>
</article>
</div>
</body>
</html>